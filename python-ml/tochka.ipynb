{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itd25Gvk3Rv4",
        "outputId": "d6eba10a-b352-430d-fae9-9a14078b05fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install langchain transformers pgvector pymongo -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWG8nRE63Rv5"
      },
      "source": [
        "# План\n",
        "- сделать текст сплиттер на каждом документе (страницах)\n",
        "- посчитать embedings в chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8YCFRRG3Rv6"
      },
      "outputs": [],
      "source": [
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5CilfDLW3Rv6"
      },
      "outputs": [],
      "source": [
        "from typing import (\n",
        "    AbstractSet,\n",
        "    Any,\n",
        "    Callable,\n",
        "    Collection,\n",
        "    Dict,\n",
        "    Iterable,\n",
        "    List,\n",
        "    Literal,\n",
        "    Optional,\n",
        "    Sequence,\n",
        "    Tuple,\n",
        "    Type,\n",
        "    TypedDict,\n",
        "    TypeVar,\n",
        "    Union,\n",
        "    cast,\n",
        ")\n",
        "import copy\n",
        "import re\n",
        "from enum import Enum\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from io import BytesIO, StringIO\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "TS = TypeVar(\"TS\", bound=\"TextSplitter\")\n",
        "\n",
        "class Language(str, Enum):\n",
        "    \"\"\"Enum of the programming languages.\"\"\"\n",
        "\n",
        "    CPP = \"cpp\"\n",
        "    GO = \"go\"\n",
        "    JAVA = \"java\"\n",
        "    KOTLIN = \"kotlin\"\n",
        "    JS = \"js\"\n",
        "    TS = \"ts\"\n",
        "    PHP = \"php\"\n",
        "    PROTO = \"proto\"\n",
        "    PYTHON = \"python\"\n",
        "    RST = \"rst\"\n",
        "    RUBY = \"ruby\"\n",
        "    RUST = \"rust\"\n",
        "    SCALA = \"scala\"\n",
        "    SWIFT = \"swift\"\n",
        "    MARKDOWN = \"markdown\"\n",
        "    LATEX = \"latex\"\n",
        "    HTML = \"html\"\n",
        "    SOL = \"sol\"\n",
        "    CSHARP = \"csharp\"\n",
        "    COBOL = \"cobol\"\n",
        "    C = \"c\"\n",
        "    LUA = \"lua\"\n",
        "    PERL = \"perl\"\n",
        "\n",
        "\n",
        "def _split_text_with_regex(\n",
        "    text: str, separator: str, keep_separator: bool\n",
        ") -> List[str]:\n",
        "    # Now that we have the separator, split the text\n",
        "    if separator:\n",
        "        if keep_separator:\n",
        "            # The parentheses in the pattern keep the delimiters in the result.\n",
        "            _splits = re.split(f\"({separator})\", text)\n",
        "            splits = [_splits[i] + _splits[i + 1] for i in range(1, len(_splits), 2)]\n",
        "            if len(_splits) % 2 == 0:\n",
        "                splits += _splits[-1:]\n",
        "            splits = [_splits[0]] + splits\n",
        "        else:\n",
        "            splits = re.split(separator, text)\n",
        "    else:\n",
        "        splits = list(text)\n",
        "    return [s for s in splits if s != \"\"]\n",
        "\n",
        "\n",
        "class Document(BaseModel):\n",
        "    \"\"\"Class for storing a piece of text and associated metadata.\"\"\"\n",
        "\n",
        "    page_content: str\n",
        "    \"\"\"String text.\"\"\"\n",
        "    metadata: dict = Field(default_factory=dict)\n",
        "    \"\"\"Arbitrary metadata about the page content (e.g., source, relationships to other\n",
        "        documents, etc.).\n",
        "    \"\"\"\n",
        "    type: Literal[\"Document\"] = \"Document\"\n",
        "\n",
        "    def __init__(self, page_content: str, **kwargs: Any) -> None:\n",
        "        \"\"\"Pass page_content in as positional or named arg.\"\"\"\n",
        "        super().__init__(page_content=page_content, **kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def is_lc_serializable(cls) -> bool:\n",
        "        \"\"\"Return whether this class is serializable.\"\"\"\n",
        "        return True\n",
        "\n",
        "    @classmethod\n",
        "    def get_lc_namespace(cls) -> List[str]:\n",
        "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
        "        return [\"langchain\", \"schema\", \"document\"]\n",
        "\n",
        "\n",
        "class TextSplitter(ABC):\n",
        "    \"\"\"Interface for splitting text into chunks.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        chunk_size: int = 4000,\n",
        "        chunk_overlap: int = 200,\n",
        "        length_function: Callable[[str], int] = len,\n",
        "        keep_separator: bool = False,\n",
        "        add_start_index: bool = False,\n",
        "        strip_whitespace: bool = True,\n",
        "    ) -> None:\n",
        "        \"\"\"Create a new TextSplitter.\n",
        "\n",
        "        Args:\n",
        "            chunk_size: Maximum size of chunks to return\n",
        "            chunk_overlap: Overlap in characters between chunks\n",
        "            length_function: Function that measures the length of given chunks\n",
        "            keep_separator: Whether to keep the separator in the chunks\n",
        "            add_start_index: If `True`, includes chunk's start index in metadata\n",
        "            strip_whitespace: If `True`, strips whitespace from the start and end of\n",
        "                              every document\n",
        "        \"\"\"\n",
        "        if chunk_overlap > chunk_size:\n",
        "            raise ValueError(\n",
        "                f\"Got a larger chunk overlap ({chunk_overlap}) than chunk size \"\n",
        "                f\"({chunk_size}), should be smaller.\"\n",
        "            )\n",
        "        self._chunk_size = chunk_size\n",
        "        self._chunk_overlap = chunk_overlap\n",
        "        self._length_function = length_function\n",
        "        self._keep_separator = keep_separator\n",
        "        self._add_start_index = add_start_index\n",
        "        self._strip_whitespace = strip_whitespace\n",
        "\n",
        "    @abstractmethod\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Split text into multiple components.\"\"\"\n",
        "\n",
        "    def create_documents(\n",
        "        self, texts: List[str], metadatas: Optional[List[dict]] = None\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Create documents from a list of texts.\"\"\"\n",
        "        _metadatas = metadatas or [{}] * len(texts)\n",
        "        documents = []\n",
        "        for i, text in enumerate(texts):\n",
        "            index = 0\n",
        "            previous_chunk_len = 0\n",
        "            for chunk in self.split_text(text):\n",
        "                metadata = copy.deepcopy(_metadatas[i])\n",
        "                if self._add_start_index:\n",
        "                    offset = index + previous_chunk_len - self._chunk_overlap\n",
        "                    index = text.find(chunk, max(0, offset))\n",
        "                    metadata[\"start_index\"] = index\n",
        "                    previous_chunk_len = len(chunk)\n",
        "                new_doc = Document(page_content=chunk, metadata=metadata)\n",
        "                documents.append(new_doc)\n",
        "        return documents\n",
        "\n",
        "    def split_documents(self, documents: Iterable[Document]) -> List[Document]:\n",
        "        \"\"\"Split documents.\"\"\"\n",
        "        texts, metadatas = [], []\n",
        "        for doc in documents:\n",
        "            texts.append(doc.page_content)\n",
        "            metadatas.append(doc.metadata)\n",
        "        return self.create_documents(texts, metadatas=metadatas)\n",
        "\n",
        "    def _join_docs(self, docs: List[str], separator: str) -> Optional[str]:\n",
        "        text = separator.join(docs)\n",
        "        if self._strip_whitespace:\n",
        "            text = text.strip()\n",
        "        if text == \"\":\n",
        "            return None\n",
        "        else:\n",
        "            return text\n",
        "\n",
        "    def _merge_splits(self, splits: Iterable[str], separator: str) -> List[str]:\n",
        "        # We now want to combine these smaller pieces into medium size\n",
        "        # chunks to send to the LLM.\n",
        "        separator_len = self._length_function(separator)\n",
        "\n",
        "        docs = []\n",
        "        current_doc: List[str] = []\n",
        "        total = 0\n",
        "        for d in splits:\n",
        "            _len = self._length_function(d)\n",
        "            if (\n",
        "                total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
        "                > self._chunk_size\n",
        "            ):\n",
        "                if total > self._chunk_size:\n",
        "                    logger.warning(\n",
        "                        f\"Created a chunk of size {total}, \"\n",
        "                        f\"which is longer than the specified {self._chunk_size}\"\n",
        "                    )\n",
        "                if len(current_doc) > 0:\n",
        "                    doc = self._join_docs(current_doc, separator)\n",
        "                    if doc is not None:\n",
        "                        docs.append(doc)\n",
        "                    # Keep on popping if:\n",
        "                    # - we have a larger chunk than in the chunk overlap\n",
        "                    # - or if we still have any chunks and the length is long\n",
        "                    while total > self._chunk_overlap or (\n",
        "                        total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
        "                        > self._chunk_size\n",
        "                        and total > 0\n",
        "                    ):\n",
        "                        total -= self._length_function(current_doc[0]) + (\n",
        "                            separator_len if len(current_doc) > 1 else 0\n",
        "                        )\n",
        "                        current_doc = current_doc[1:]\n",
        "            current_doc.append(d)\n",
        "            total += _len + (separator_len if len(current_doc) > 1 else 0)\n",
        "        doc = self._join_docs(current_doc, separator)\n",
        "        if doc is not None:\n",
        "            docs.append(doc)\n",
        "        return docs\n",
        "\n",
        "    @classmethod\n",
        "    def from_huggingface_tokenizer(cls, tokenizer: Any, **kwargs: Any) -> \"TextSplitter\":\n",
        "        \"\"\"Text splitter that uses HuggingFace tokenizer to count length.\"\"\"\n",
        "        try:\n",
        "            from transformers import PreTrainedTokenizerBase\n",
        "\n",
        "            if not isinstance(tokenizer, PreTrainedTokenizerBase):\n",
        "                raise ValueError(\n",
        "                    \"Tokenizer received was not an instance of PreTrainedTokenizerBase\"\n",
        "                )\n",
        "\n",
        "            def _huggingface_tokenizer_length(text: str) -> int:\n",
        "                return len(tokenizer.encode(text))\n",
        "\n",
        "        except ImportError:\n",
        "            raise ValueError(\n",
        "                \"Could not import transformers python package. \"\n",
        "                \"Please install it with `pip install transformers`.\"\n",
        "            )\n",
        "        return cls(length_function=_huggingface_tokenizer_length, **kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def from_tiktoken_encoder(\n",
        "        cls: Type[TS],\n",
        "        encoding_name: str = \"gpt2\",\n",
        "        model_name: Optional[str] = None,\n",
        "        allowed_special: Union[Literal[\"all\"], AbstractSet[str]] = set(),\n",
        "        disallowed_special: Union[Literal[\"all\"], Collection[str]] = \"all\",\n",
        "        **kwargs: Any,\n",
        "    ) -> TS:\n",
        "        \"\"\"Text splitter that uses tiktoken encoder to count length.\"\"\"\n",
        "        try:\n",
        "            import tiktoken\n",
        "        except ImportError:\n",
        "            raise ImportError(\n",
        "                \"Could not import tiktoken python package. \"\n",
        "                \"This is needed in order to calculate max_tokens_for_prompt. \"\n",
        "                \"Please install it with `pip install tiktoken`.\"\n",
        "            )\n",
        "\n",
        "        if model_name is not None:\n",
        "            enc = tiktoken.encoding_for_model(model_name)\n",
        "        else:\n",
        "            enc = tiktoken.get_encoding(encoding_name)\n",
        "\n",
        "        def _tiktoken_encoder(text: str) -> int:\n",
        "            return len(\n",
        "                enc.encode(\n",
        "                    text,\n",
        "                    allowed_special=allowed_special,\n",
        "                    disallowed_special=disallowed_special,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if issubclass(cls, TokenTextSplitter):\n",
        "            extra_kwargs = {\n",
        "                \"encoding_name\": encoding_name,\n",
        "                \"model_name\": model_name,\n",
        "                \"allowed_special\": allowed_special,\n",
        "                \"disallowed_special\": disallowed_special,\n",
        "            }\n",
        "            kwargs = {**kwargs, **extra_kwargs}\n",
        "\n",
        "        return cls(length_function=_tiktoken_encoder, **kwargs)\n",
        "\n",
        "    def transform_documents(\n",
        "        self, documents: Sequence[Document], **kwargs: Any\n",
        "    ) -> Sequence[Document]:\n",
        "        \"\"\"Transform sequence of documents by splitting them.\"\"\"\n",
        "        return self.split_documents(list(documents))\n",
        "\n",
        "\n",
        "class RecursiveCharacterTextSplitter(TextSplitter):\n",
        "    \"\"\"Splitting text by recursively look at characters.\n",
        "\n",
        "    Recursively tries to split by different characters to find one\n",
        "    that works.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        separators: Optional[List[str]] = None,\n",
        "        keep_separator: bool = True,\n",
        "        is_separator_regex: bool = False,\n",
        "        **kwargs: Any,\n",
        "    ) -> None:\n",
        "        \"\"\"Create a new TextSplitter.\"\"\"\n",
        "        super().__init__(keep_separator=keep_separator, **kwargs)\n",
        "        self._separators = separators or [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "        self._is_separator_regex = is_separator_regex\n",
        "\n",
        "    def _split_text(self, text: str, separators: List[str]) -> List[str]:\n",
        "        \"\"\"Split incoming text and return chunks.\"\"\"\n",
        "        final_chunks = []\n",
        "        # Get appropriate separator to use\n",
        "        separator = separators[-1]\n",
        "        new_separators = []\n",
        "        for i, _s in enumerate(separators):\n",
        "            _separator = _s if self._is_separator_regex else re.escape(_s)\n",
        "            if _s == \"\":\n",
        "                separator = _s\n",
        "                break\n",
        "            if re.search(_separator, text):\n",
        "                separator = _s\n",
        "                new_separators = separators[i + 1 :]\n",
        "                break\n",
        "\n",
        "        _separator = separator if self._is_separator_regex else re.escape(separator)\n",
        "        splits = _split_text_with_regex(text, _separator, self._keep_separator)\n",
        "\n",
        "        # Now go merging things, recursively splitting longer texts.\n",
        "        _good_splits = []\n",
        "        _separator = \"\" if self._keep_separator else separator\n",
        "        for s in splits:\n",
        "            if self._length_function(s) < self._chunk_size:\n",
        "                _good_splits.append(s)\n",
        "            else:\n",
        "                if _good_splits:\n",
        "                    merged_text = self._merge_splits(_good_splits, _separator)\n",
        "                    final_chunks.extend(merged_text)\n",
        "                    _good_splits = []\n",
        "                if not new_separators:\n",
        "                    final_chunks.append(s)\n",
        "                else:\n",
        "                    other_info = self._split_text(s, new_separators)\n",
        "                    final_chunks.extend(other_info)\n",
        "        if _good_splits:\n",
        "            merged_text = self._merge_splits(_good_splits, _separator)\n",
        "            final_chunks.extend(merged_text)\n",
        "        return final_chunks\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        return self._split_text(text, self._separators)\n",
        "\n",
        "    @classmethod\n",
        "    def from_language(\n",
        "        cls, language: Language, **kwargs: Any\n",
        "    ) -> \"RecursiveCharacterTextSplitter\":\n",
        "        separators = cls.get_separators_for_language(language)\n",
        "        return cls(separators=separators, is_separator_regex=True, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_separators_for_language(language: Language) -> List[str]:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M_b6s7SE3Rv7"
      },
      "outputs": [],
      "source": [
        "test_text = \"расходов по операциям приобретенными ценными бумагами): 10.4.2 бухгалтерском учете кредитной организации заемщика данная операция отражается как приобретение заимствованных ценных бумаг в соответствии с главой 3 настоящего Положения Одновременно обязательство по возврату заимствованных ценных бумаг списывается сО счета & 91314 <Ценные бумаги, полученные по операциям, совершаемым на возвратной основеж случае если обязательство По возврату заимствованных ценных бумаг учтено на балансовом счете По учету привлеченных средств случае реализации заимствованных ценных бумаг); сумма денежных средств; предоставленных погашение займа, отражастся ПО дебету балансового счета По учету выбытия   (реализации) ценных бумаг; обязательство По возврату заимствованных ценных бумаг по кредиту балансового счета по учету выбытия (реализации) ценных бумаг. Одноврсменно сумма остатка (при сго наличии), образовавшаяся на счете & 61210 <Выбытие (реализация) ценных бумагъ, подлежит отнесению на счета & 70601 <Доходых или & 70606 <Расходыж (по символу доходов От операций приобретенными ценными бумагами или расходов По операциям приобретенными ценными бумагами) 10.5. Процентные расходы По операциям займа ценных бумаг процентные доходЫ От операций   займа ценных бумаг отражаются учетом следующего 10.5.1. Начисление и уплата процентов По договору займа ценных бумаг учитывается кредитной  организацией засмщиком на балансовых счетах по учету начисленных процентов (к уплате) ПО привлеченным средствам Начисление процентного расхода по договору займа ценных бумаг отражается бухгалтерской записью:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-CsIrF1V3Rv7"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=2048,\n",
        "    chunk_overlap=409,\n",
        "    length_function=len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FDxRmpP53Rv8"
      },
      "outputs": [],
      "source": [
        "splits = splitter.split_text(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K9bh78Xi3Rv8"
      },
      "outputs": [],
      "source": [
        "dsn = \"mongodb://LasuriaRobert:HilbertSpace@larek.tech:9500/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vzMhMISF3Rv8"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "client = MongoClient(dsn)\n",
        "materials = client[\"cbr\"].get_collection(\"materials_copy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jRQ2wftA3Rv8"
      },
      "outputs": [],
      "source": [
        "res = materials.find({\"invalid\": False}).limit(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHjmG39v3Rv8"
      },
      "outputs": [],
      "source": [
        "from langchain.core import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=2048,\n",
        "    chunk_overlap=409,\n",
        "    length_function=len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5bopAHff3Rv8"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "material = namedtuple(\"material\", [\"doc\", \"page\", \"text\", \"src\"])\n",
        "\n",
        "docs = [\n",
        "    material(obj[\"doc\"], obj[\"page\"], obj[\"text\"], obj[\"src\"]) for obj in\n",
        "    res\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ekWXe9nS3Rv8"
      },
      "outputs": [],
      "source": [
        "_docs = [\n",
        "    Document(page_content=doc.text, metadata={\n",
        "        \"src\":doc.src\n",
        "    })\n",
        "    for doc in docs\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2PBIIF0D3Rv9"
      },
      "outputs": [],
      "source": [
        "result = splitter.split_documents(\n",
        "    _docs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aMsmC873Rv9",
        "outputId": "15d2b462-fae4-4e3b-857b-3c09f1b58083"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='ЦЕНТРАЛЬНЫЙ БАНК РОССИЙСКОЙ ФЕДЕРАЦИИ (БАНК РОССИИ) УК А 3 А НИЕ 11 онтября 2018г х\\' 4930-У г Москва  ЗЮГТГРСНН РЕТИЩЦИ {ИЕЛЙЕ*ЕП МЕЛЕРЖШП ЗаевгмстРивОЁАе Рсгистрацнонкый ж 53109 24\"92 [2щЖ внесенин изменений в Положение Банка России от 19 июня 2012 года Л: 383-П к0 правилах осуществления перевода денежных средствэ соответствии пунктом статьи Федерального закона От 10 июля 2002 года & 86-Ф3 <0 Центральном банке Российской Федерации (Банке России)э (Собрание законодательства Российской Федерации, 2002, ) 28, ст: 2790; 2003, ) 2, ст: 157; & 52, ст. 5032; 2004, & 27, с 2711; ) 31, ст. 3233; 2005, &\\' 25, ст. 2426, &: 30, сТ: 3101; 2006, & 19, ст: 2061; & 25, ст. 2648; 2007, & 1, ст. 9, ст. 10; &е 10, Ст 1151; & 18, ст. 2117; 2008, & 42, СТ: 4696, сТ: 4699; &: 44, ст: 4982; & 52, ст: 6229, 6231; 2009, )\\' 1, с: 25; &\\' 29, СТ 3629, &\\' 48, ст: 5731; 2010, &\\' 45, ст: 5756; 2011, & 7, сТ 907; & 27, С: 3873; & 43, ст: 5973; Л 48, СТ: 6728; 2012, &\\' 50, ст: 6954; &\\' 53, СТ 7591, СТ: 7607; 2013, & 11, сТ: 1076; & 14, сТ: 1649; )! 19, ст. 2329; & 27, ст. 3438, сТ: 3476, СТ: 3477; &\\' 30, ст: 4084; & 49, 6336; & 51, 6695, ст. 6699; )\\' 52, ст. 6975; 2014, &\\' 19, ст. 2311 ст: 2317; Л 27, ст. 3634; Л 30, ст. 4219; &\\' 40, сТ. 5318; && 45, СТ. 6154; &@ 52, сТ: 7543; 2015, )! 1, СТ. 4, ст. 37; . 27, сТ 3958, сТ: 4001; &\\' 29, СТ 4348, СТ: 4357; &\\' 41, ст: 5639; &! 48, ст. 6699; 2016, & 1, ст. 23, ст. 46, ст. 50; & 26,', metadata={'src': 'https://www.cbr.ru/Queries/UniDbQuery/File/90134/704'}, type='Document')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "result[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NTU0AZJh3Rv9"
      },
      "outputs": [],
      "source": [
        "model_name = \"Tochka-AI/ruRoPEBert-e5-base-2k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0JSL-Oi3Rv9",
        "outputId": "ab6f344d-0701-46ef-aa37-1982093818cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Tochka-AI/ruRoPEBert-e5-base-2k:\n",
            "- modeling_rope_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_name = \"Tochka-AI/ruRoPEBert-e5-base-2k\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_name, trust_remote_code=True, attn_implementation=\"eager\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtuuUL3q4OGB",
        "outputId": "06927308-47d8-43ad-f7dc-42c2489212e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m112.6/156.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "from typing import (\n",
        "    Any,\n",
        "    Dict,\n",
        "    List,\n",
        "    Optional,\n",
        ")\n",
        "\n",
        "\n",
        "class Embeddings(ABC):\n",
        "    \"\"\"Interface for embedding models.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Embed search docs.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        \"\"\"Embed query text.\"\"\"\n",
        "\n",
        "\n",
        "DEFAULT_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "\n",
        "class HuggingFaceEmbeddings(BaseModel, Embeddings):\n",
        "    \"\"\"HuggingFace sentence_transformers embedding models.\n",
        "\n",
        "    To use, you should have the ``sentence_transformers`` python package installed.\n",
        "\n",
        "    Example:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "            model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "            model_kwargs = {'device': 'cpu'}\n",
        "            encode_kwargs = {'normalize_embeddings': False}\n",
        "            hf = HuggingFaceEmbeddings(\n",
        "                model_name=model_name,\n",
        "                model_kwargs=model_kwargs,\n",
        "                encode_kwargs=encode_kwargs\n",
        "            )\n",
        "    \"\"\"\n",
        "    client: Any = None  #: :meta private:\n",
        "    model_name: str = DEFAULT_MODEL_NAME\n",
        "    \"\"\"Model name to use.\"\"\"\n",
        "    cache_folder: Optional[str] = None\n",
        "    \"\"\"Path to store models.\n",
        "    Can be also set by SENTENCE_TRANSFORMERS_HOME environment variable.\"\"\"\n",
        "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
        "    \"\"\"Keyword arguments to pass to the model.\"\"\"\n",
        "    encode_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
        "    \"\"\"Keyword arguments to pass when calling the `encode` method of the model.\"\"\"\n",
        "    multi_process: bool = False\n",
        "    \"\"\"Run encode() on multiple GPUs.\"\"\"\n",
        "    show_progress: bool = False\n",
        "    \"\"\"Whether to show a progress bar.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs: Any):\n",
        "        \"\"\"Initialize the sentence_transformer.\"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        try:\n",
        "            import sentence_transformers\n",
        "\n",
        "        except ImportError as exc:\n",
        "            raise ImportError(\n",
        "                \"Could not import sentence_transformers python package. \"\n",
        "                \"Please install it with `pip install sentence-transformers`.\"\n",
        "            ) from exc\n",
        "\n",
        "        self.client = sentence_transformers.SentenceTransformer(\n",
        "            self.model_name, cache_folder=self.cache_folder, **self.model_kwargs\n",
        "        )\n",
        "\n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "\n",
        "        extra = \"forbid\"\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Compute doc embeddings using a HuggingFace transformer model.\n",
        "\n",
        "        Args:\n",
        "            texts: The list of texts to embed.\n",
        "\n",
        "        Returns:\n",
        "            List of embeddings, one for each text.\n",
        "        \"\"\"\n",
        "        import sentence_transformers\n",
        "\n",
        "        texts = list(map(lambda x: x.replace(\"\\n\", \" \"), texts))\n",
        "        if self.multi_process:\n",
        "            pool = self.client.start_multi_process_pool()\n",
        "            embeddings = self.client.encode_multi_process(texts, pool)\n",
        "            sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n",
        "        else:\n",
        "            embeddings = self.client.encode(\n",
        "                texts, show_progress_bar=self.show_progress, **self.encode_kwargs\n",
        "            )\n",
        "\n",
        "        return embeddings.tolist()\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        \"\"\"Compute query embeddings using a HuggingFace transformer model.\n",
        "\n",
        "        Args:\n",
        "            text: The text to embed.\n",
        "\n",
        "        Returns:\n",
        "            Embeddings for the text.\n",
        "        \"\"\"\n",
        "        return self.embed_documents([text])[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3VBb_o4BsJ",
        "outputId": "66f7ccae-6bcb-4482-a10e-2743954c79a2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sCf3Ai53Rv9",
        "outputId": "20e56934-e567-4f66-928e-b2115cca64ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name Tochka-AI/ruRoPEBert-e5-base-2k. Creating a new one with MEAN pooling.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at Tochka-AI/ruRoPEBert-e5-base-2k and are newly initialized: ['bert.embeddings.position_embeddings.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedings = HuggingFaceEmbeddings(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clickhouse-driver -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4rV4QMBZCL",
        "outputId": "27c7f353-d2ce-4e5a-e4ef-6776ad2da1e8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/935.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/935.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/935.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m778.2/935.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m935.1/935.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "d72UEadR3Rv-",
        "outputId": "8fe411ca-c6f4-481f-ce86-95f39e5f058f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnexpectedPacketFromServerError",
          "evalue": "Code: 102. Unexpected packet from server larek.tech:65002 (expected Hello or Exception, got Unknown packet)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnexpectedPacketFromServerError\u001b[0m           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-0a5a6b4555f4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m client = Client(host=\"larek.tech\", port=65002,\n\u001b[1;32m      4\u001b[0m                               user=\"testuser\", password=\"superstrongpassword\")\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SHOW TABLES\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# conn = connect(host=\"larek.tech\", port=65002, user=\"testuser\", password=\"superstrongpassword\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# cursor = conn.cursor()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, params, with_column_types, external_tables, query_id, settings, types_check, columnar)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;31m# INSERT queries can use list/tuple/generator of list/tuples/dicts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# For SELECT parameters can be passed in only in dict right now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mdisconnect_on_error\u001b[0;34m(self, query, settings)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdisconnect_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mestablish_connection\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_query_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/connection.py\u001b[0m in \u001b[0;36mforce_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/connection.py\u001b[0m in \u001b[0;36m_init_connection\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_hello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_hello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mrevision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_revision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_driver/connection.py\u001b[0m in \u001b[0;36mreceive_hello\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m                                                      packet_type)\n\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedPacketFromServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_addendum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnexpectedPacketFromServerError\u001b[0m: Code: 102. Unexpected packet from server larek.tech:65002 (expected Hello or Exception, got Unknown packet)"
          ]
        }
      ],
      "source": [
        "from clickhouse_driver import connect, Client\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import pprint\n",
        "\n",
        "def create_table(client: Client, table_name: str = \"ann_index_example\"):\n",
        "    client.execute(\"SET allow_experimental_annoy_index = 1\")\n",
        "    client.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {table_name}\n",
        "     (\n",
        "       DocName String,\n",
        "       Metadata String,\n",
        "       embedding Array(Float32),\n",
        "      INDEX ann_index_1 embedding TYPE annoy('cosineDistance')\n",
        "     )\n",
        "     ENGINE = MergeTree\n",
        "     ORDER BY DocName;\"\"\")\n",
        "\n",
        "\n",
        "def create_embs(model, documents: list, client: Client, table_name: str = \"ann_index_example\"):\n",
        "    embeddings = []\n",
        "\n",
        "    for re in tqdm(documents):\n",
        "        emb = model.encode(re.page_content)\n",
        "        embeddings.append((re.page_content, re.metadata['src'], emb))\n",
        "\n",
        "    client.execute(\n",
        "        f'INSERT INTO {table_name} VALUES',\n",
        "        embeddings)\n",
        "    client.disconnect()\n",
        "\n",
        "\n",
        "def search_similarity(model, query: str, client: Client, k: int = 1,\n",
        "                      table_name: str = \"ann_index_example\") -> list:\n",
        "    emb_q = model.encode(query)\n",
        "\n",
        "    return client.execute(f\"\"\" SELECT DocName, Metadata, embedding, L2Distance(embedding, %(emb)s) AS score\n",
        "    FROM {table_name}\n",
        "    ORDER BY score ASC\n",
        "    LIMIT %(k)s\n",
        "    \"\"\", {\"emb\": list(emb_q), \"k\": k})\n",
        "\n",
        "\n",
        "model = SentenceTransformer(\"Tochka-AI/ruRoPEBert-e5-base-2k\")\n",
        "client = Client(\"localhost\")\n",
        "\n",
        "# create_table(client)\n",
        "# create_embs(model=model, client=client, documents=result)\n",
        "\n",
        "query = \"Что такое банковская ликвидность? Как банки ее используют?\"\n",
        "retrieved_documents = search_similarity(model, query, client, k=5)\n",
        "for r in retrieved_documents:\n",
        "    pprint.pprint(r[0])\n",
        "    pprint.pprint(r[1])\n",
        "    pprint.pprint(r[3])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tta6-Bhi3Rv-"
      },
      "outputs": [],
      "source": [
        "def retrieve_vector_db(query, db, n_results=3):\n",
        "    return db.similarity_search(query, n_results)\n",
        "\n",
        "\n",
        "query = \"Как назначается временная администрация?\"\n",
        "retrieved_docs = retrieve_vector_db(query=query, db=chroma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYIE7z_T3Rv-",
        "outputId": "17a00b9b-9760-4125-a2f8-62ec447b484b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Предложение саморегулируемую организацию арбитражных управляющих, имеющую первый порядковый номер в Списке: 1.9. Банк   России должен направлять саморегулируемой организации арбитражных управляющих Прсдложение способом, предусмотренным пунктом 1.6 настоящего Указания. 1.10. Саморегулируемая организация арбитражных управляющих получившая Предложение имеющая намерение представить кандидатуры руководителя и членов временной администрации финансовой организации, должна направить Банк России уведомление представлении кандидатур руководителя и членов временной администрации финансовой организации (далее Уведомление саморегулируемой организации арбитражных управляющих ), включающее следующие сведения: наименование финансовой организации, которую назначается временная администрация; фамилия; Имя, отчество (при наличии) идентификационный номер налогоплательщика кандидатуры руководителя временной администрации; фамилия; ИМЯ, отчество (при наличии) идентификационный номер налогоплательщика каждой ИЗ кандидатур членов временной администрации; сведения; подтверждающие согласие кандидатуры руководителя временной администрации быть назначенным руководителем   временной администрации; сведения; подтверждающие согласие каждой кандидатур членов временной администрации быть назначенной членом временной администрации; сведения, подтвсрждающис соответствие кандидатуры руководителя временной администрации требованиям; установленным статьей 18325 Федерального закона <0 несостоятельности (банкротстве) ; сведения отношении каждой из кандидатур членов временной администрации; подтверждающие   отсутствие   обстоятельств; указанных', metadata={'src': 'https://www.cbr.ru/Queries/UniDbQuery/File/90134/764'}),\n",
              " Document(page_content='сведения об объеме полномочий назначаемой временной администрации (в том числе указание на назначение временной администрации ограничением или приостановлением полномочий исполнительных органов финансовой организации); срок деятельности временной администрации; предложенис представить кандидатуры членов временной администрации числа ЛИЦ; отношении которых отсутствуют обстоятельства; указанные пункте статьи 1836   Федерального закона <0 несостоятельности (банкротстве)  выразивших согласие быть назначснными членами временной администрации; указание на ТО, чТО кандидатуры членов временной администрации должны быть представлены Банк России не позднее трех рабочих дней следующих за днем получения Обращения. 1.13 Саморегулируемая организация сфере финансового рынка; членом которой является финансовая организация которая имест намерение представить кандидатуры члснов временной администрации финансовой организации; должна направить в Банк России уведомление представлении кандидатур членов   временной администрации финансовой организации (далее Уведомление саморегулируемой организации сфере финансового рынка), включающее следующис сведения: наименованис финансовой организации; которую назначастся временная администрация; фамилия; ИМЯ, отчество (при наличии) идентификационный номер налогоплательщика каждой ИЗ кандидатур членов временной администрации; сведения; подтверждающие согласие каждой из кандидатур членов временной администрации быть назначенной членом временной администрации; сведения отношении каждой кандидатур членов временной администрации; подтверждающие отсутствие обстоятельств;   указанных', metadata={'src': 'https://www.cbr.ru/Queries/UniDbQuery/File/90134/764'}),\n",
              " Document(page_content='полное фирменное сокращенное фирменное (при наличии) наименования кредитной организации; регистрационный номер дату регистрации; место нахождения кредитной организации; наименование федерального закона ссылку на статью (пункт, подпункт) на основании которой принято решенис назначении временной администрации; срок действия временной администрации; сведения составе временной администрации руководителе временной администрации; заместителе руководителя временной администрации (при необходимости) членах  временной администрации указанием Их фамилий; имен; отчеств (при наличии) занимаемых должностей); перечень главных задач функций; возложенных на временную администрацию; перечень полномочий  временной администрации; также указание на ограничение ИЛи приостановление полномочий исполнительных органов кредитной организации (при наличии); положение об уведомлении Банком России банков-корреспондентов (в том числе нерезидентов) 0 назначении временной администрации; положения включении указанного приказа Банка России Единый федеральный реестр сведений 0 банкротстве и об опубликовании указанного приказа Банка России <Вестнике Банка Россиих соответствии пунктом 3 статьн Федерального закона <О несостоятельности (банкротстве) : Приказ Банка   России назначении временной администрации можст содержать другие положения, необходимые ДЛЯ выполнения задач функций; возложенных на временную администрацию, 2.5. Приказ Банка России назначении временной администрации доводитсЯ Департаментом финансового оздоровления ДО подразделения; осуществляющего надзор деятельностью кредитной организации; 18926', metadata={'src': 'https://www.cbr.ru/Queries/UniDbQuery/File/90134/358'})]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQArKkpK3Rv-"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import Ollama\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "ollama = Ollama(base_url=\"http://larek.tech:11434\", model=\"llama2\", temperature=0)\n",
        "\n",
        "template = \"\"\"\n",
        "Отвечай только на русском. Если пишешь на другом языке, переводи его на русской.\n",
        "Если не знаешь ответа, скажи что не знаешь ответа, не пробуй отвечать.\n",
        "Я дам тебе три текста, из которых надо дать ответ на поставленный вопрос.\n",
        "Также тебе надо оставить ссылку из источник.\n",
        "\n",
        "Context:\n",
        "источник {url1}:\n",
        "{context1}\n",
        "\n",
        "источник {url2}:\n",
        "{context2}\n",
        "\n",
        "источник {url3}:\n",
        "{context3}\n",
        "\n",
        "Вопрос: {question} на русском языке. Ответь на вопрос основываясь на данных документах\n",
        "Развернутый ответ:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=ollama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9XuenLi3Rv-"
      },
      "outputs": [],
      "source": [
        "query = \"Какое отношение к денежно-кредитной политике имеет управление ликвидностью банковского сектора и ставками денежного рынка, которое осуществляет Банк России?\"\n",
        "docs = retrieve_vector_db(query, chroma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9_rO1_o3Rv-"
      },
      "outputs": [],
      "source": [
        "generated = llm_chain.run(\n",
        "    context1=docs[0].page_content,\n",
        "    url1=docs[0].metadata[\"src\"],\n",
        "    context2=docs[1].page_content,\n",
        "    url2=docs[1].metadata[\"src\"],\n",
        "    context3=docs[2].page_content,\n",
        "    url3=docs[2].metadata[\"src\"],\n",
        "    question=query,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSK9DshQ3Rv-",
        "outputId": "cc84816c-cab3-4a43-e00b-8aeadf974122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ответ: Управление ликвидностью банковского сектора и ставками денежного рынка, которое осуществляет Банк России, играет важную роль в регулировании денежно-кредитной политики в России.\n",
            "\n",
            "Согласно документам, на сайте ЦБ РФ, управление ликвидностью банковского сектора и ставками денежного рынка является частью довольно широкого круга функций, которые выполняются Банком России для регулирования денежно-кредитной политики. В частности, это включает в себя:\n",
            "\n",
            "1. Контроль выполнения кредитными организациями обязательных резервных требований, установленных Банком России;\n",
            "2. Оценку и контроль рисков, связанных с операциями на финансовых рынках;\n",
            "3. Разработку и применение методов и инструментов для мониторинга и регулирования денежно-кредитной политики;\n",
            "4. Обучение и развитие кредитных организаций, а также увеличение их конкурентоспособности на рынке;\n",
            "5. Решение задач по обеспечению стабильности финансовой системы России;\n",
            "6. Разработка и применение методов и инструментов для мониторинга и регулирования ликвидности на денежном рынке;\n",
            "7. Обучение и развитие специалистов в области денежно-кредитной политики и ликвидности на денежном рынке.\n",
            "\n",
            "Таким образом, управление ликвидностью банковского сектора и ставками денежного рынка играет важную роль в регулировании денежно-кредитной политики в России и является одним из ключевых элементов довольно широкого круга функций, которые выполняются Банком России для обеспечения стабильности финансовой системы России.\n"
          ]
        }
      ],
      "source": [
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er8AG3063Rv-",
        "outputId": "2d8b737e-ef05-49b2-80d0-3f7f51e0aa18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Советник первого заместителя (заместителя) Председателя Центрального банка Российской Федерации Советник главного аудитора Центрального банка Российской Федерации Дирсктор дспартамента Начальник департамента Руководитель службы Директор Университета Банка России Первый заместитель (заместитель) главного   бухгалтера   Центрального банка Российской Федерации первый заместитель (заместитель) директора Департамента бухгалтерского и отчстности Первый заместитель (заместитель) директора Департамента бухгалтерского учета отчетности, Департамента исследований прогнозирования Департамента наличного денежного обращения; Департамента   национальной   платежной системы,  Департамента допуска прекращения деятельности финансовых организаций; Департамента финансового оздоровления, Департамента корпоративных отношений Департамента обеспечения банковского   надзора; Департамента банковского регулирования; Департамента надзора за системно значимыми кредитными организациями; Департамента операций на финансовых рынках Операционного департамента; Департамента финансовой стабильности, Департамента финансового мониторинга валюотного контроля; Департамента  денежно-кредитной политики, Департамента стратегического развития финансового рынка, Департамента страхового рынка, Департамента инвестиционных финансовых посредников; Департамента   инфраструктуры финансового рынка, Департамента микрофинансового рынка, Департамента управлсния данными; Департамента противодействия недобросовестным практикам, Юридического департамента; Департамента внутреннего аудита, Департамента безопасности Банка   России;   Департамента информационной безопасности, Департамента регулирования бухгалтерского учета учста\n",
            "Консультант Заместитель начальника отдела Заведующий сектором Главный экономист 2.1.7. Все ДОЛЖНОСТИ Дспартамента надзора системно значимыми кредитными организациями 2.1.8. Все должности Службы текущего банковского надзора 2.1.9. Все должности Главной инспекции Банка России 2.1.10. Департамент операций на финансовых рынках 2.1.10.1. Управление операций на внутреннем рынке Советник экономический 2.1.10.1.1. Отдел операций с ценными бумагами Главный дилер 2.1.10.1.1.1 Все должности сектора операций на открытом рынке 2.1.10.1.1.2. Все должности сектора клиентских операций 2.1.10.2 Все должности Управления операций на внешних рынках 2.1.10.3. Все должности Управления кредитования банков и проведения депозитных операций 2.1.10.4. Управление оценки и контроля рисков Начальник Управления Заместитель начальника Управления Руководитель направления 2.1.11. Операционный департамент 2.1.11.1. Все должности Управления допуска и сопровождения операций на финансовых рынках 2.1.12. Дспартамент финансовой стабильности Советник экономический 2.1.12.1. Управление рисков финансовых рынков и стресс-тестирования Начальник Управления Заместитель начальника Управления\n",
            "контроля и противодействия легализации (отмыванию) доходов; полученных преступным путем; и финансирования терроризма): 2.2. В Центре финансового мониторинга и валютного контроля: Заместитель начальника центра 3, В территориальных учреждениях Банка России: 3.1. Руководители: Начальник главного управления Центрального банка Российской Федерации; Первый заместитель начальника главного управления   Центрального банка Российской Федерации; Заместитель начальника главного управления Центрального банка Российской Федерации; Управляющий отделением главного управления   Центрального банка Российской Федерации; Управляющий отделением национальным банком главного управления Центрального банка Российской Федерации; Заместитель управляющего отделением главного управления Центрального банка Российской Федерации; Заместитель управляющего отделением национальным банком главного управления Центрального банка Российской Федерации: 3,2.В структурных подразделениях территориальных учреждений Банка России (должности служащих Банка России приведены согласно функциям подразделений; определяемым соответствии положениями подразделениях на уровне управления, отдела, сектора): 3.2.1. структурных   подразделениях; осуществляющих контроль выполнением кредитными организациями обязательных резервных требований: Начальник управления (отдела); Заместитель начальника управления (отдела); Заведующий сектором:\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(doc.page_content, end=\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}